{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "# NLP: Analyzing Review Text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import ujson as json\n",
    "\n",
    "with gzip.open('yelp_train_academic_dataset_review_reduced.json.gz') as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Scikit Learn will want the labels in a separate data structure, so let's pull those out now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "stars = [row['stars'] for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "\n",
    "class ColumnSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col_names):\n",
    "        self.col_names = col_names  # We will need these in transform()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # This transformer doesn't need to learn anything about the data,\n",
    "        # so it can just return self without any further processing\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):             \n",
    "        return [row[col] for col in self.col_names for row in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mytokenizer(string):\n",
    "    tokenized=[]\n",
    "    for t in string:\n",
    "        doc = nlp(t)\n",
    "        tokens = [token.lemma_ for token in doc if not token.is_punct]\n",
    "        tokens = [token.lower() for token in tokens \n",
    "                  if token.lower() not in stop_words_lemma]\n",
    "        tokens = [token for token in tokens if token != '-pron-']\n",
    "        string=\" \".join(tokens)\n",
    "        tokenized.append(string)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\",\n",
       " \"If you like lot lizards, you'll love the Pine Cone!\"]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cst=ColumnSelectTransformer(['text'])\n",
    "X=cst.fit_transform(data[:2])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['know dr. goldberg like   arizona let tell stay away doctor office dr. johnson leave goldberg johnson leave care doctor interest co pay come medication refill month refill patient financial situation trying 90 day mail away pharmacy prescription guy joke matter wrong office staff incompetent 90 time office voice mail answer return adult child husband decide leave practice experience frustration entire office attitude like favor break stay away doc practice deserve well need feel compel write bad review meet pathetic excuse doctor money',\n",
       " 'like lot lizard love pine cone']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytokenizer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## bag_of_words_model: Using Hash Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cst', ColumnSelectTransformer(col_names=['text'])),\n",
       "                ('cv',\n",
       "                 HashingVectorizer(alternate_sign=True, analyzer='word',\n",
       "                                   binary=False, decode_error='strict',\n",
       "                                   dtype=<class 'numpy.float64'>,\n",
       "                                   encoding='utf-8', input='content',\n",
       "                                   lowercase=True, n_features=1048576,\n",
       "                                   ngram_range=(1, 1), norm='l2',\n",
       "                                   preprocessor=None, stop_words=None,\n",
       "                                   strip_accents=None,\n",
       "                                   token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                   tokenizer=None)),\n",
       "                ('predictor',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words_est = Pipeline([\n",
    "    # Column selector (remember the ML project?)\n",
    "    ('cst', ColumnSelectTransformer(['text'])),\n",
    "    # Vectorizer\n",
    "    ('cv', HashingVectorizer()),\n",
    "    # Frequency filter (if necessary)\n",
    "    # Regressor\n",
    "    ('predictor',Ridge())\n",
    "])\n",
    "#gs=GridSearchCV(bag_of_words_est,param_grid=parameters)\n",
    "bag_of_words_est.fit(data, stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## normalized_model: Using TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cst', ColumnSelectTransformer(col_names=['text'])),\n",
       "                ('cv',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('predictor',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "normalized_est = Pipeline([\n",
    "    # Column selector (remember the ML project?)\n",
    "    ('cst', ColumnSelectTransformer(['text'])),\n",
    "    # Vectorizer\n",
    "    ('cv', TfidfVectorizer()),\n",
    "    # Frequency filter (if necessary)\n",
    "    # Regressor\n",
    "    ('predictor',Ridge())\n",
    "])\n",
    "#gs=GridSearchCV(bag_of_words_est,param_grid=parameters)\n",
    "normalized_est.fit(data, stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## bigram_model: Including Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cst', ColumnSelectTransformer(col_names=['text'])),\n",
       "                ('cv',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('predictor',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "bigram_est = Pipeline([\n",
    "    # Column selector (remember the ML project?)\n",
    "    ('cst', ColumnSelectTransformer(['text'])),\n",
    "    # Vectorizer\n",
    "    ('cv', TfidfVectorizer(ngram_range=(1,2))),\n",
    "    # Frequency filter (if necessary)\n",
    "    # Regressor\n",
    "    ('predictor',Ridge())\n",
    "])\n",
    "#gs=GridSearchCV(bag_of_words_est,param_grid=parameters)\n",
    "bigram_est.fit(data, stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "## food_bigrams: Find the bigrams that show up frequently in food context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "with gzip.open('yelp_train_academic_dataset_business.json.gz') as f:\n",
    "    business_data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Each row of this file corresponds to a single business.  The category key gives a list of categories for each; take all where \"Restaurants\" appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': 'vcNAWiLM4dR7D2nwwJ7nCA',\n",
       " 'full_address': '4840 E Indian School Rd\\nSte 101\\nPhoenix, AZ 85018',\n",
       " 'hours': {'Tuesday': {'close': '17:00', 'open': '08:00'},\n",
       "  'Friday': {'close': '17:00', 'open': '08:00'},\n",
       "  'Monday': {'close': '17:00', 'open': '08:00'},\n",
       "  'Wednesday': {'close': '17:00', 'open': '08:00'},\n",
       "  'Thursday': {'close': '17:00', 'open': '08:00'}},\n",
       " 'open': True,\n",
       " 'categories': ['Doctors', 'Health & Medical'],\n",
       " 'city': 'Phoenix',\n",
       " 'review_count': 7,\n",
       " 'name': 'Eric Goldberg, MD',\n",
       " 'neighborhoods': [],\n",
       " 'longitude': -111.983758,\n",
       " 'state': 'AZ',\n",
       " 'stars': 3.5,\n",
       " 'latitude': 33.499313,\n",
       " 'attributes': {'By Appointment Only': True},\n",
       " 'type': 'business'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurants=[]\n",
    "for b in business_data:\n",
    "    if \"Restaurants\" in b['categories']:\n",
    "        restaurants.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12876"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(restaurants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "restaurant_ids = [r['business_id'] for r in restaurants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "assert len(restaurant_ids) == 12876"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "The \"business_id\" here is the same as in the review data.  Use this to extract the review text for all reviews of restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business_id': 'JwUE5GmEO-sH1FuwJgKBlQ',\n",
       " 'full_address': '6162 US Highway 51\\nDe Forest, WI 53532',\n",
       " 'hours': {},\n",
       " 'open': True,\n",
       " 'categories': ['Restaurants'],\n",
       " 'city': 'De Forest',\n",
       " 'review_count': 26,\n",
       " 'name': 'Pine Cone Restaurant',\n",
       " 'neighborhoods': [],\n",
       " 'longitude': -89.335844,\n",
       " 'state': 'WI',\n",
       " 'stars': 4.0,\n",
       " 'latitude': 43.238893,\n",
       " 'attributes': {'Take-out': True,\n",
       "  'Good For': {'dessert': False,\n",
       "   'latenight': False,\n",
       "   'lunch': True,\n",
       "   'dinner': False,\n",
       "   'breakfast': False,\n",
       "   'brunch': False},\n",
       "  'Caters': False,\n",
       "  'Noise Level': 'average',\n",
       "  'Takes Reservations': False,\n",
       "  'Delivery': False,\n",
       "  'Ambience': {'romantic': False,\n",
       "   'intimate': False,\n",
       "   'touristy': False,\n",
       "   'hipster': False,\n",
       "   'divey': False,\n",
       "   'classy': False,\n",
       "   'trendy': False,\n",
       "   'upscale': False,\n",
       "   'casual': False},\n",
       "  'Parking': {'garage': False,\n",
       "   'street': False,\n",
       "   'validated': False,\n",
       "   'lot': True,\n",
       "   'valet': False},\n",
       "  'Has TV': True,\n",
       "  'Outdoor Seating': False,\n",
       "  'Attire': 'casual',\n",
       "  'Alcohol': 'none',\n",
       "  'Waiter Service': True,\n",
       "  'Accepts Credit Cards': True,\n",
       "  'Good for Kids': True,\n",
       "  'Good For Groups': True,\n",
       "  'Price Range': 1},\n",
       " 'type': 'business'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'votes': {'funny': 0, 'useful': 0, 'cool': 0},\n",
       " 'user_id': 'Qrs3EICADUKNFoUq2iHStA',\n",
       " 'review_id': '_ePLBPrkrf4bhyiKWEn4Qg',\n",
       " 'stars': 1,\n",
       " 'date': '2013-04-19',\n",
       " 'text': \"I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\",\n",
       " 'type': 'review',\n",
       " 'business_id': 'vcNAWiLM4dR7D2nwwJ7nCA'}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253272"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uGykseHzyS5xAMWoN6YUqA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LRKJF43s9-3jG9Lgx4zODg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RgDg-k9S5YD_BaxMckifkg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_wZTYYL7cutanzAnJUTGMA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id\n",
       "0  JwUE5GmEO-sH1FuwJgKBlQ\n",
       "1  uGykseHzyS5xAMWoN6YUqA\n",
       "2  LRKJF43s9-3jG9Lgx4zODg\n",
       "3  RgDg-k9S5YD_BaxMckifkg\n",
       "4  _wZTYYL7cutanzAnJUTGMA"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_df=pd.DataFrame(data)[['business_id','text']]\n",
    "r_df=pd.DataFrame(restaurants)[['business_id']]\n",
    "r_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143361, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=r_df.merge(data_df, on='business_id',how='left').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>If you like lot lizards, you'll love the Pine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>Only went here once about a year and a half ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>Ate a Saturday morning breakfast at the Pine C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>This is definitely not your usual truck stop. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JwUE5GmEO-sH1FuwJgKBlQ</td>\n",
       "      <td>I like this location better than the one near ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               text\n",
       "0  JwUE5GmEO-sH1FuwJgKBlQ  If you like lot lizards, you'll love the Pine ...\n",
       "1  JwUE5GmEO-sH1FuwJgKBlQ  Only went here once about a year and a half ag...\n",
       "2  JwUE5GmEO-sH1FuwJgKBlQ  Ate a Saturday morning breakfast at the Pine C...\n",
       "3  JwUE5GmEO-sH1FuwJgKBlQ  This is definitely not your usual truck stop. ...\n",
       "4  JwUE5GmEO-sH1FuwJgKBlQ  I like this location better than the one near ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res=df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "restaurant_reviews = [row['text'] for row in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": null
   },
   "outputs": [],
   "source": [
    "assert len(restaurant_reviews) == 143361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you like lot lizards, you'll love the Pine Cone!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "#dill.dump(restaurant_reviews,open('reviews.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dill\n",
    "restaurant_reviews = dill.load(open('reviews.pkd', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": null
   },
   "source": [
    "Calculate:\n",
    "\n",
    "  $$ \\frac{p(w_1 w_2)}{p(w_1) p(w_2)} $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##count single words\n",
    "cv = CountVectorizer(min_df=20,stop_words='english')\n",
    "single=cv.fit_transform(restaurant_reviews)\n",
    "\n",
    "grams=list(cv.get_feature_names())\n",
    "counts = single.sum(axis=0).A1\n",
    "\n",
    "freq_distribution = Counter(dict(zip(grams, counts)))\n",
    "\n",
    "#count double words\n",
    "cv = CountVectorizer(ngram_range=(2,2),min_df=20,stop_words='english')\n",
    "double = cv.fit_transform(restaurant_reviews)\n",
    "\n",
    "bigrams=list(cv.get_feature_names())\n",
    "counts_bi = double.sum(axis=0).A1\n",
    "\n",
    "freq_distribution_bi = Counter(dict(zip(bigrams, counts_bi)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##calculate p(w)\n",
    "value=sum(freq_distribution.values())\n",
    "for item, count in freq_distribution.items():\n",
    "    freq_distribution[item]+=30 \n",
    "    freq_distribution[item]/= value\n",
    "\n",
    "##calculate p(w1w2)\n",
    "value=sum(freq_distribution_bi.values())\n",
    "for item, count in freq_distribution_bi.items():\n",
    "    freq_distribution_bi[item] /= value\n",
    "\n",
    "##calculate ratio\n",
    "for item, count in freq_distribution_bi.items():\n",
    "    lis_grams=item.split()\n",
    "    value1=freq_distribution[lis_grams[0]]\n",
    "    value2=freq_distribution[lis_grams[1]]\n",
    "    value=value1*value2\n",
    "    freq_distribution_bi[item] /= value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top100=[item[0] for item in freq_distribution_bi.most_common(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['knick knacks',\n",
       " 'rula bula',\n",
       " 'ropa vieja',\n",
       " 'itty bitty',\n",
       " 'dac biet',\n",
       " 'gulab jamun',\n",
       " 'patatas bravas',\n",
       " 'puerto rican',\n",
       " 'wal mart',\n",
       " 'bradley ogden',\n",
       " 'lomo saltado',\n",
       " 'vice versa',\n",
       " 'valle luna',\n",
       " 'kao tod',\n",
       " 'sous vide',\n",
       " 'artery clogging',\n",
       " 'har gow',\n",
       " 'pina colada',\n",
       " 'bells whistles',\n",
       " 'harry potter',\n",
       " 'aguas frescas',\n",
       " 'ping pang',\n",
       " 'casey moore',\n",
       " 'pin kaow',\n",
       " 'cochinita pibil',\n",
       " 'scantily clad',\n",
       " 'demi glace',\n",
       " 'lactose intolerant',\n",
       " 'thit nuong',\n",
       " 'kilt lifter',\n",
       " 'moscow mule',\n",
       " 'woody allen',\n",
       " 'hustle bustle',\n",
       " 'dulce leche',\n",
       " 'cabo wabo',\n",
       " 'kee mao',\n",
       " 'mt everest',\n",
       " 'tres leches',\n",
       " 'arnold palmer',\n",
       " 'coca cola',\n",
       " 'stainless steel',\n",
       " 'kool aid',\n",
       " 'rick moonen',\n",
       " 'osso bucco',\n",
       " 'van buren',\n",
       " 'huli huli',\n",
       " 'fleur lys',\n",
       " 'insult injury',\n",
       " 'quench thirst',\n",
       " 'bok choy',\n",
       " 'fogo chao',\n",
       " 'jean philippe',\n",
       " 'toby keith',\n",
       " 'tilted kilt',\n",
       " 'identity crisis',\n",
       " 'parmigiano reggiano',\n",
       " 'hush puppies',\n",
       " 'sierra bonita',\n",
       " 'nba finals',\n",
       " 'panna cotta',\n",
       " 'apache junction',\n",
       " 'petit fours',\n",
       " 'hong kong',\n",
       " 'peter piper',\n",
       " 'dean martin',\n",
       " 'lechon kawali',\n",
       " 'sauvignon blanc',\n",
       " 'osso buco',\n",
       " 'kare kare',\n",
       " 'pet peeve',\n",
       " 'croque madame',\n",
       " 'willy wonka',\n",
       " 'adam richman',\n",
       " 'alice wonderland',\n",
       " 'wi fi',\n",
       " 'santa fe',\n",
       " 'pang pong',\n",
       " 'nail coffin',\n",
       " 'monte carlo',\n",
       " 'conveyor belt',\n",
       " 'lau lau',\n",
       " 'daniel boulud',\n",
       " 'agua fresca',\n",
       " 'dietary restrictions',\n",
       " 'jean georges',\n",
       " 'caffe boa',\n",
       " 'pei wei',\n",
       " 'huevos rancheros',\n",
       " 'ho hum',\n",
       " 'johnny rockets',\n",
       " 'joel robuchon',\n",
       " 'tar tar',\n",
       " 'beaten path',\n",
       " 'du jour',\n",
       " 'wolfgang puck',\n",
       " 'bon appetit',\n",
       " 'flip flops',\n",
       " 'beverly hills',\n",
       " 'loco moco',\n",
       " 'cous cous']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
